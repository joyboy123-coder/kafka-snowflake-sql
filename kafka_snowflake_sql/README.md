# ğŸ“Œ Real-Time Stock Data Processing with Kafka & Snowflake ğŸš€  

This project **simulates real-time stock data streaming** using **Apache Kafka** and stores the processed data in **Snowflake**.  

- **Producer** ğŸ¯ â†’ Sends random stock price data to Kafka.  
- **Consumer** ğŸ“¥ â†’ Reads data from Kafka and loads it into **Snowflake**.  
- **Optimized Snowflake Performance** âš¡ â†’ Implemented **Materialized Views, Result Caching, and Clustering** for better query performance.  

---

## **1ï¸âƒ£ Project Structure ğŸ—ï¸**  

### **ğŸ”¹ Config Folder (`config/`) ğŸ› ï¸**  
- **`kafka_config.py`** â†’ Contains **Kafka bootstrap server and topic name**.  
- **`consumer_config.py`** â†’ Holds **Kafka consumer settings**.  
- **`snowflake_config.py`** â†’ Stores **Snowflake credentials** like **account, username, password, database, and warehouse**.  

### **ğŸ”¹ Logs Folder (`logs/`) ğŸ“‚**  
- Initially, the **logs folder is empty**.  
- Once you **run the producer and consumer**, logs are generated and stored inside this folder.  

---

## **2ï¸âƒ£ Producer: `stock_producer.py` ğŸ“¤**  

### **ğŸ”¹ What It Does?**  
- Generates **random stock prices** for companies like **AAPL, GOOGL, MSFT, AMZN, TSLA**.  
- Creates a **JSON payload** with stock symbol, price, and timestamp.  
- Sends the stock data to **Kafka topic** in real time.  
- Uses a **logger** to track every message sent.  
- Runs in an **infinite loop**, generating stock data every **2 seconds** to simulate real-time updates.  

---

## **3ï¸âƒ£ Consumer: `stock_consumer.py` ğŸ“¥**  

### **ğŸ”¹ What It Does?**  
- Reads stock data from **Kafka topic**.  
- Stores the data in **Snowflake** using a **Pandas DataFrame**.  
- Batches **5 records at a time** before inserting into Snowflake.  
- Uses **write_pandas** for efficient data loading.  
- Logs every successful insertion into **Snowflake** in the **logs folder**.  

---

## **4ï¸âƒ£ Snowflake Optimizations âš¡**  

To improve **query performance and efficiency**, I implemented:  

### **ğŸ”¹ Materialized Views ğŸ“Š**  
- Created **Materialized Views** to precompute and store **aggregated stock data**, reducing query execution time.  

### **ğŸ”¹ Result Caching ğŸš€**  
- **Enabled result caching** to speed up repeated queries by avoiding recomputation.  

### **ğŸ”¹ Clustering ğŸ”„**  
- **Used clustering** on frequently queried columns (like `SYMBOL` and `TIMESTAMP`) to optimize storage and retrieval.  

---

## **5ï¸âƒ£ Summary âœ…**  
âœ” **Kafka configurations** are stored in **`config/kafka_config.py` and `config/consumer_config.py`**.  
âœ” **Snowflake credentials** are in **`config/snowflake_config.py`**.  
âœ” **Logs are stored** in the `logs/` folder after running the scripts.  
âœ” **Producer** sends **random stock prices** to Kafka every 2 seconds.  
âœ” **Consumer** retrieves stock data from Kafka and inserts it into **Snowflake**.  
âœ” **Optimized performance** using **Materialized Views, Result Caching, and Clustering** in Snowflake.  

ğŸš€ **Now, you have a real-time stock data pipeline running with Kafka & Snowflake!**  
